{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markovSentences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjeUUoHXBqyKXgZli7l7NA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jben-hun/colab_notebooks/blob/master/algorithms/markovSentences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2iNJVQVEgA"
      },
      "source": [
        "# Text generation with nth order Markov chain models trained on reddit data\n",
        "The probability $P(\\ word_{m}\\ \\mid\\ word_{m-1}\\ \\land\\ word_{m-2}\\ \\land\\ \\cdots\\ \\land\\ word_{m-n}\\ )$ is proportional to and is derived from the relative occurences of such sequence of words in the training dataset, where $n$ is the order of the Markov chain model.\n",
        "\n",
        "Example with a chain of order $n=2:$\n",
        "\n",
        "$\\cdots\\ word_{m-3}\\ (word_{m-2}\\ word_{m-1})\\rightarrow(word_{m}$</font>$)\\ word_{m+1}\\ \\cdots$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEw4MXYzEpwO"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDh1P8w8bjPh",
        "outputId": "56e57452-e1b5-45fc-ca6c-fd2e29e8f60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!pip install -q praw\n",
        "\n",
        "import praw\n",
        "import re\n",
        "import random\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from collections import deque\n",
        "\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "\n",
        "client_id = \"\" #@param {type:\"string\"}\n",
        "client_secret = \"\" #@param {type:\"string\"}\n",
        "user_agent = \"\" #@param {type:\"string\"}\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=client_id,\n",
        "    client_secret=client_secret,\n",
        "    user_agent=user_agent)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 153kB 2.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 8.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWUQX6EAKptQ"
      },
      "source": [
        "SUBREDDITS = (\"askreddit\", \"explainlikeimfive\", \"dankmemes\")\n",
        "\n",
        "\n",
        "class RedditMarkovChain:\n",
        "    def __init__(\n",
        "            self,\n",
        "            subreddit,\n",
        "            order=1,\n",
        "            sentence_limit=1000,\n",
        "            begin_str=\"*BEGIN*\",\n",
        "            end_str=\"*END*\",\n",
        "            cycle_str=\"*CYCLE*\",\n",
        "            train_split=(0.9),\n",
        "            test_split=None):\n",
        "        self.__subreddit = subreddit\n",
        "        self.__order = order\n",
        "        # first order: word1 -> word2\n",
        "        # second order: (word1, word2) -> word3\n",
        "        # ...\n",
        "        self.__sentence_limit = sentence_limit\n",
        "        self.__begin_str = begin_str\n",
        "        self.__end_str = end_str\n",
        "        self.__cycle_str = cycle_str\n",
        "        self.__train_split = train_split\n",
        "\n",
        "        self.__test_split = (test_split if test_split is not None\n",
        "                            else (1.0 - train_split))\n",
        "        \n",
        "        self.__sentences = self.mine_subreddit(\n",
        "            subreddit=reddit.subreddit(self.subreddit),\n",
        "            sentence_limit=self.sentence_limit)\n",
        "\n",
        "        self.model = self.__build_model()\n",
        "\n",
        "    def __build_model(self):\n",
        "        \"\"\"Build a markov chain model from extracted sentences\"\"\"\n",
        "\n",
        "        model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "        for sentence in self.train_sentences:\n",
        "            words = ([self.begin_str] +\n",
        "                     self.__split_sentence(sentence) +\n",
        "                     [self.end_str])\n",
        "            for i in range(1, len(words)):\n",
        "                for j in range(i-1, i-self.order-1, -1):\n",
        "                    if j < 0:\n",
        "                        break\n",
        "                    key = self.__convert_to_key(words[j:i])\n",
        "                    model[key][words[i]] += 1\n",
        "\n",
        "        return model\n",
        "\n",
        "    def __convert_to_key(self, values):\n",
        "        \"\"\"Pads with None values to until the length is equal to the order\"\"\"\n",
        "        assert len(values) <= self.order\n",
        "        return tuple([None]*(self.order - len(values)) + values)\n",
        "\n",
        "    def __get_longest_key(self, l, keys):\n",
        "        \"\"\"Returns the longest subkey that exist in the model,\n",
        "        or the full key if no subkey was found\"\"\"\n",
        "\n",
        "        for i in range(len(l)-1):\n",
        "            key = tuple(l[i:])\n",
        "            if key in keys:\n",
        "                return key\n",
        "\n",
        "        # if no existing key was found, return the full key, so the defaultdict\n",
        "        # creates an entry for it with a count value of zero\n",
        "        return tuple(l)\n",
        "\n",
        "    def __split_sentence(self, sentence):\n",
        "        \"\"\"Split sentences into words\"\"\"\n",
        "        return re.findall(r\"((?:[\\w']+)|(?:[,!.?]))\", sentence)\n",
        "\n",
        "    def __get_prob(self, key, word):\n",
        "        \"\"\"Get single probability from word counts\"\"\"\n",
        "        return (0 if word not in self.model[key]\n",
        "                else self.model[key][word]/sum(self.model[key].values()))\n",
        "\n",
        "    def __get_all_probs(self, key):\n",
        "        \"\"\"Get all probabilities from word counts\"\"\"\n",
        "        n = sum(self.model[key].values())\n",
        "        return [v/n for v in self.model[key].values()]\n",
        "\n",
        "    def generate(self, method=\"sample\"):\n",
        "        \"\"\"Generate text using the created markov chain model\n",
        "\n",
        "        method:\n",
        "            expected: choose most likely words, infinite cycles are possible\n",
        "            random: choose words uniformly\n",
        "            sample: choose words based on the modeled probabilities\n",
        "        \"\"\"\n",
        "\n",
        "        sentence = []\n",
        "        word = self.begin_str\n",
        "        key = self.__convert_to_key([word])\n",
        "\n",
        "        if method == \"expected\":\n",
        "            used = set()\n",
        "\n",
        "        while True:\n",
        "            if method == \"expected\":\n",
        "                word = max(\n",
        "                    self.model[key].items(), key=lambda x: x[1])[0]\n",
        "            elif method == \"random\":\n",
        "                word = random.choice(tuple(self.model[key].items()))[0]\n",
        "            elif method == \"sample\":\n",
        "                words = tuple(self.model[key].keys())\n",
        "                probs = self.__get_all_probs(key)\n",
        "                word = np.random.choice(words, p=probs)\n",
        "            if word == self.end_str:\n",
        "                break\n",
        "\n",
        "            sentence.append(word)\n",
        "\n",
        "            key = self.__convert_to_key(sentence[-self.order:])\n",
        "\n",
        "            if method == \"expected\":\n",
        "                if key in used:\n",
        "                    sentence.append(f\"{self.cycle_str}\")\n",
        "                    break\n",
        "                used.add(key)\n",
        "\n",
        "        return (\" \".join(sentence).replace(\" .\", \".\")\n",
        "                                  .replace(\" ?\", \"?\")\n",
        "                                  .replace(\" !\", \"!\")\n",
        "                                  .replace(\" ,\", \",\"))\n",
        "\n",
        "    def classify(self, sentence):\n",
        "        \"\"\"Deduce the most likely source of a sentence\"\"\"\n",
        "\n",
        "        p = 1\n",
        "\n",
        "        words = ([self.begin_str] +\n",
        "                 self.__split_sentence(sentence) +\n",
        "                 [self.end_str])\n",
        "\n",
        "        for i in range(1, len(words)):\n",
        "            key = self.__get_longest_key(\n",
        "                self.__convert_to_key(words[max(0, i-self.order):i]),\n",
        "                self.model.keys())\n",
        "            p *= self.__get_prob(key, words[i])\n",
        "\n",
        "        return p\n",
        "\n",
        "    @staticmethod\n",
        "    def mine_subreddit(subreddit, sentence_limit):\n",
        "        \"\"\"Extract clean sentences from submissions and comments\"\"\"\n",
        "\n",
        "        # re that matches clean sentences\n",
        "        matcher = re.compile(r\"(?:[.!?] |^)[A-Z][\\w', ]+[.!?](?= [A-Z]|$)\")\n",
        "\n",
        "        sentences = []\n",
        "\n",
        "        with tqdm.tqdm(total=sentence_limit) as pbar:\n",
        "            for submission in subreddit.hot(limit=None):\n",
        "                sentences += matcher.findall(submission.title)\n",
        "                sentences += matcher.findall(submission.selftext)\n",
        "\n",
        "                submission.comment_sort = \"best\"\n",
        "\n",
        "                comments = [\n",
        "                    comment.body for comment in submission.comments.list()\n",
        "                    if not isinstance(comment, praw.models.MoreComments)]\n",
        "\n",
        "                for comment in comments:\n",
        "                    sentences += matcher.findall(comment)\n",
        "\n",
        "                if len(sentences) >= sentence_limit:\n",
        "                    random.shuffle(sentences)\n",
        "                    pbar.update(sentence_limit - pbar.n)\n",
        "                    break\n",
        "                else:\n",
        "                    pbar.update(len(sentences) - pbar.n)\n",
        "\n",
        "        return [sentence.lstrip(\".!? \")\n",
        "                        .replace(\"won't\", \"will not\")\n",
        "                        .replace(\"n't\", \" not\")\n",
        "                        .replace(\"'m\", \" am\")\n",
        "                        .replace(\"'re\", \" are\")\n",
        "                        for sentence in sentences[:sentence_limit]]\n",
        "\n",
        "    @property\n",
        "    def subreddit(self):\n",
        "        return self.__subreddit\n",
        "\n",
        "    @property\n",
        "    def sentences(self):\n",
        "        return self.__sentences\n",
        "\n",
        "    @property\n",
        "    def order(self):\n",
        "        return self.__order\n",
        "\n",
        "    @property\n",
        "    def sentence_limit(self):\n",
        "        return self.__sentence_limit\n",
        "\n",
        "    @property\n",
        "    def begin_str(self):\n",
        "        return self.__begin_str\n",
        "\n",
        "    @property\n",
        "    def end_str(self):\n",
        "        return self.__end_str\n",
        "\n",
        "    @property\n",
        "    def cycle_str(self):\n",
        "        return self.__cycle_str\n",
        "\n",
        "    @property\n",
        "    def train_split(self):\n",
        "        return self.__train_split\n",
        "\n",
        "    @property\n",
        "    def test_split(self):\n",
        "        return self.__test_split\n",
        "\n",
        "    @property\n",
        "    def train_sentences(self):\n",
        "        return self.sentences[:int(len(self.sentences)*self.train_split)]\n",
        "\n",
        "    @property\n",
        "    def test_sentences(self):\n",
        "        return self.sentences[int(len(self.sentences)*self.train_split):]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD3OnLbKEvfF"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_DTLJWHdpR9"
      },
      "source": [
        "**Construct markov chains for each specified subreddit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGoyfE3idaXk",
        "outputId": "c6ed7747-388f-4373-8d4a-afff2ed12d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "chains = {subreddit: RedditMarkovChain(subreddit, order=2, sentence_limit=1000)\n",
        "          for subreddit in SUBREDDITS}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:13<00:00, 76.25it/s]\n",
            "100%|██████████| 1000/1000 [00:36<00:00, 27.68it/s]\n",
            "100%|██████████| 1000/1000 [00:27<00:00, 35.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRVVf74Jpq7r"
      },
      "source": [
        "**Deriving most probable sentence for each model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqMPhSKlY2UG",
        "outputId": "02364880-b790-4163-ebce-4e8b1aa14f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for subreddit, chain in chains.items():\n",
        "    print(f\"{subreddit}: {chain.generate('expected')}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "askreddit: I was at a young age.\n",
            "explainlikeimfive: The problem with strictly widening a base, while maintaining perpendicular wheels, is there really any point?\n",
            "dankmemes: I am not a arest' of the movie.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v-kULdBpY6Z"
      },
      "source": [
        "**Generating new text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDInUB-pnBSY",
        "outputId": "447727cc-73ec-402b-d67b-a5aeb144be6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "dict_data = defaultdict(lambda: [])\n",
        "\n",
        "for subreddit, chain in chains.items():\n",
        "    for _ in range(5):\n",
        "        sentence = chain.generate()\n",
        "        dict_data[\"sentence\"].append(sentence)\n",
        "        dict_data[\"model\"].append(subreddit)\n",
        "\n",
        "        for k, v in chains.items():\n",
        "            p = v.classify(sentence)\n",
        "            dict_data[f\"P({k})\"].append(p)\n",
        "\n",
        "display(pd.DataFrame(dict_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>model</th>\n",
              "      <th>P(askreddit)</th>\n",
              "      <th>P(explainlikeimfive)</th>\n",
              "      <th>P(dankmemes)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>And it was great to see us do better in the neck.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>3.283425e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yep.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>3.333333e-03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.002222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They have the Democrats would control the Senate, and it would cost the city less money to simply buy Norman and his mum a house far far away than to keep his mouth shut about the actual state of being in love.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>6.977041e-11</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mitch's interests are focused on my own spit I want that put in my own car.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>1.102293e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Congrats, onward with your journey.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>5.555556e-04</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A great example of this lap the runners will be separated by the stagger so there are parts of the lower body are some of these things.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.419278e-10</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Thanks for powerfully refuting your own horrible idea.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.111111e-03</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The answer is not really explain it well, but also a matter of how anything floats is that you can try this easily.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.627817e-11</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PC games are made to run properly on your system, kidneys and digestion.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.314815e-05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Enough slack that it will interfere with the clock and yourself.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.736111e-06</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Im a minor and seeing those girls in those provocative positions and clothing isnt ok.</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What I said, with utter confidence, that it'd become a square.</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How.</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The cum accelerates.</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.005556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Well played.</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                              sentence  ... P(dankmemes)\n",
              "0                                                                                                                                                                    And it was great to see us do better in the neck.  ...     0.000000\n",
              "1                                                                                                                                                                                                                 Yep.  ...     0.002222\n",
              "2   They have the Democrats would control the Senate, and it would cost the city less money to simply buy Norman and his mum a house far far away than to keep his mouth shut about the actual state of being in love.  ...     0.000000\n",
              "3                                                                                                                                          Mitch's interests are focused on my own spit I want that put in my own car.  ...     0.000000\n",
              "4                                                                                                                                                                                  Congrats, onward with your journey.  ...     0.000000\n",
              "5                                                                              A great example of this lap the runners will be separated by the stagger so there are parts of the lower body are some of these things.  ...     0.000000\n",
              "6                                                                                                                                                               Thanks for powerfully refuting your own horrible idea.  ...     0.000000\n",
              "7                                                                                                  The answer is not really explain it well, but also a matter of how anything floats is that you can try this easily.  ...     0.000000\n",
              "8                                                                                                                                             PC games are made to run properly on your system, kidneys and digestion.  ...     0.000000\n",
              "9                                                                                                                                                     Enough slack that it will interfere with the clock and yourself.  ...     0.000000\n",
              "10                                                                                                                              Im a minor and seeing those girls in those provocative positions and clothing isnt ok.  ...     0.001111\n",
              "11                                                                                                                                                      What I said, with utter confidence, that it'd become a square.  ...     0.000139\n",
              "12                                                                                                                                                                                                                How.  ...     0.001111\n",
              "13                                                                                                                                                                                                The cum accelerates.  ...     0.005556\n",
              "14                                                                                                                                                                                                        Well played.  ...     0.001111\n",
              "\n",
              "[15 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMyrKXKJpl_J"
      },
      "source": [
        "**Classifying real text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J92CBICZnTrg",
        "outputId": "14bf1d49-78c5-4006-a3d5-0d822257cc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "dict_data = defaultdict(lambda: [])\n",
        "\n",
        "for subreddit, chain in chains.items():\n",
        "    for sentence in chain.test_sentences[:5]:\n",
        "        dict_data[\"sentence\"].append(sentence)\n",
        "        dict_data[\"source\"].append(subreddit)\n",
        "\n",
        "        for k, v in chains.items():\n",
        "            p = v.classify(sentence)\n",
        "            dict_data[f\"P({k})\"].append(p)\n",
        "\n",
        "display(pd.DataFrame(dict_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>source</th>\n",
              "      <th>P(askreddit)</th>\n",
              "      <th>P(explainlikeimfive)</th>\n",
              "      <th>P(dankmemes)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sixth grade end of year trip, we were at a ropes course park where you'd rock climb and walked across tall catwalks and the like.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Our reality is a fiction created by a higher civilization of higher beings who wrote a story and transformed it into a reality and every move, breath, even blink, is already programmed.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mitch is really old.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Choking to death alone is honestly my biggest fear.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The logic was similar for us, yes.</td>\n",
              "      <td>askreddit</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>On my PC, just the BIOS takes longer than that.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>No, only 4 left and 5 right.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HAHA.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Why is it that being slapped in the face will make you cry, stubing your toe makes you inhale rendering you speechless and being burnt by hot water will make you growl or scream?</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kernel API is for abstracting away the nasty parts of communicating with the operating system.</td>\n",
              "      <td>explainlikeimfive</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>My pain is far greater than yours!</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Really?</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.001111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Weird flex warning!</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Is this 1984?</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>After ten spurts you start to worry.</td>\n",
              "      <td>dankmemes</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                     sentence  ... P(dankmemes)\n",
              "0                                                           Sixth grade end of year trip, we were at a ropes course park where you'd rock climb and walked across tall catwalks and the like.  ...     0.000000\n",
              "1   Our reality is a fiction created by a higher civilization of higher beings who wrote a story and transformed it into a reality and every move, breath, even blink, is already programmed.  ...     0.000000\n",
              "2                                                                                                                                                                        Mitch is really old.  ...     0.000000\n",
              "3                                                                                                                                         Choking to death alone is honestly my biggest fear.  ...     0.000000\n",
              "4                                                                                                                                                          The logic was similar for us, yes.  ...     0.000000\n",
              "5                                                                                                                                             On my PC, just the BIOS takes longer than that.  ...     0.000000\n",
              "6                                                                                                                                                                No, only 4 left and 5 right.  ...     0.000000\n",
              "7                                                                                                                                                                                       HAHA.  ...     0.000000\n",
              "8          Why is it that being slapped in the face will make you cry, stubing your toe makes you inhale rendering you speechless and being burnt by hot water will make you growl or scream?  ...     0.000000\n",
              "9                                                                                              Kernel API is for abstracting away the nasty parts of communicating with the operating system.  ...     0.000000\n",
              "10                                                                                                                                                         My pain is far greater than yours!  ...     0.000000\n",
              "11                                                                                                                                                                                    Really?  ...     0.002222\n",
              "12                                                                                                                                                                        Weird flex warning!  ...     0.000000\n",
              "13                                                                                                                                                                              Is this 1984?  ...     0.000000\n",
              "14                                                                                                                                                       After ten spurts you start to worry.  ...     0.000000\n",
              "\n",
              "[15 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqPVLY7jEIW1"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvTiyWstD104"
      },
      "source": [
        "*   https://en.wikipedia.org/wiki/Markov_chain\n",
        "*   https://www.reddit.com/r/SubredditSimulator/comments/3g9ioz/what_is_rsubredditsimulator/\n",
        "*   https://www.reddit.com/r/SubSimulatorGPT2/comments/btfhks/what_is_rsubsimulatorgpt2/"
      ]
    }
  ]
}